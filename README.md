# ğŸ¥ YouTube to Blog MVP

Convert any YouTube video into a well-structured blog post using AI! This MVP combines a Streamlit frontend with a FastAPI backend, powered by LangChain and local Ollama for video-to-blog conversion.

## ğŸ—ï¸ Architecture

```
Frontend (Streamlit) â†’ Backend (FastAPI) â†’ LangChain â†’ Ollama (llama3.2)
                                      â†“
                               YouTube Transcript API
```

## âœ¨ Features

-  **Simple UI**: Clean Streamlit interface for easy YouTube URL input
-  **Real-time Processing**: See progress as your video is converted
-  **AI-Powered**: Uses LangChain with local Ollama (llama3.2) for content generation
-  **Structured Output**: Generates well-formatted blog posts with headings
-  **Download Support**: Export your blog as Markdown
-  **Error Handling**: Comprehensive error messages and validation

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.13+** installed
2. **Ollama** installed with llama3.2 model
   ```bash
   # Install Ollama from https://ollama.ai/
   ollama pull llama3.2
   ```

### Installation

1. **Clone or navigate to the project directory**
2. **The startup scripts will automatically handle virtual environment and dependencies**

### ğŸ¯ Running the MVP

#### Option 1: Automatic Startup (Recommended)

**Both scripts will automatically:**

-  âœ… Create a Python virtual environment if it doesn't exist
-  âœ… Activate the virtual environment
-  âœ… Install all required dependencies
-  âœ… Check Ollama and install llama3.2 model if needed
-  âœ… Start both backend and frontend services

```bash
# Windows PowerShell (Recommended)
.\start_mvp.ps1

# Cross-platform Python script
python run_mvp.py
```

#### Option 2: Manual Setup

If you prefer manual control:

1. **Create and activate virtual environment**:

   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\Activate.ps1

   # Linux/Mac
   python -m venv venv
   source venv/bin/activate
   ```

2. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

3. **Start services manually**:

   ```bash
   # Terminal 1 - Backend
   fastapi run stream.py --port 8001

   # Terminal 2 - Frontend
   streamlit run frontend.py --server.port 8501
   ```

4. **Open your browser** to `http://localhost:8501`

## ğŸ”§ Virtual Environment Benefits

The automated scripts ensure:

-  âœ… **Isolated dependencies** - No conflicts with system Python packages
-  âœ… **Consistent environment** - Same setup across different machines
-  âœ… **Easy cleanup** - Just delete the `venv` folder to remove everything
-  âœ… **Reproducible builds** - Exact dependency versions from requirements.txt

1. **Start the backend** (Terminal 1):

   ```bash
   fastapi run stream.py --port 8001
   ```

2. **Start the frontend** (Terminal 2):

   ```bash
   streamlit run frontend.py --server.port 8501
   ```

3. **Open your browser** to `http://localhost:8501`

## ğŸ“± How to Use

1. **Enter YouTube URL**: Paste any YouTube video URL with available transcripts
2. **Generate Blog**: Click the "Generate Blog Post" button
3. **Wait for Processing**: The AI will extract transcript and generate content
4. **Read & Download**: View your blog post and download as Markdown

## ğŸ”§ API Endpoints

-  `GET /` - API information
-  `GET /health` - Health check
-  `POST /generate-blog` - Generate blog from YouTube URL
-  `GET /docs` - Interactive API documentation

## ğŸ“ Project Structure

```
â”œâ”€â”€ frontend.py              # Streamlit frontend
â”œâ”€â”€ stream.py               # FastAPI backend
â”œâ”€â”€ run_mvp.py             # Python startup script
â”œâ”€â”€ start_mvp.ps1          # PowerShell startup script
â”œâ”€â”€ main.py                # CLI version (existing)
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ yt_tool.py        # YouTube transcript extraction
â”‚   â”œâ”€â”€ blog_researcher.py # Blog outline generation
â”‚   â””â”€â”€ blog_writer.py    # Blog content generation
â””â”€â”€ config/
    â””â”€â”€ llm_config.py     # Ollama configuration
```

## ğŸ¨ Screenshots

The MVP provides:

-  Clean input interface for YouTube URLs
-  Real-time progress indicators
-  Markdown-formatted blog output
-  Download functionality
-  Error handling and troubleshooting

## ğŸ” Troubleshooting

### Common Issues

1. **Port 8000 already in use**

   -  The MVP uses port 8001 for backend to avoid conflicts

2. **Cannot connect to backend**

   -  Ensure FastAPI is running: `fastapi run stream.py --port 8001`
   -  Check if Ollama is running: `ollama list`

3. **Virtual environment issues**

   -  If manual setup: ensure virtual environment is activated
   -  Delete `venv` folder and re-run startup script to recreate
   -  On Windows: ensure execution policy allows PowerShell scripts

4. **Transcript not available**

   -  Some videos don't have transcripts
   -  Try videos with auto-generated captions

5. **Slow generation**

   -  Local Ollama processing can take 1-3 minutes depending on video length
   -  Consider using a more powerful model if available

6. **PowerShell execution policy (Windows)**
   ```powershell
   Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
   ```

### Health Checks

-  Backend health: `http://localhost:8001/health`
-  Test transcript: `http://localhost:8001/test-transcript/{video_id}`
-  Virtual environment: Check if `venv` folder exists and contains packages

## ğŸš€ Future Enhancements

-  **Video length optimization** - Handle longer videos
-  **Multiple language support** - Support non-English videos
-  **Custom prompts** - Allow users to customize blog style
-  **Batch processing** - Process multiple videos
-  **Export formats** - PDF, HTML, etc.
-  **User authentication** - Save and manage blog posts

## ğŸ“ License

This project is for educational and demonstration purposes.

## ğŸ¤ Contributing

Feel free to submit issues and enhancement requests!
